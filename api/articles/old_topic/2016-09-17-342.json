{"title":"Scrapy快速写爬虫","uid":"a0f1485d8813f2781144a51b0a71a712","slug":"old_topic/2016-09-17-342","date":"2016-09-17T14:50:18.000Z","updated":"2024-03-16T11:44:51.882Z","comments":true,"path":"api/articles/old_topic/2016-09-17-342.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"content":"<p>看到别人的教程，学着测了一下，不错。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scrapy startproject ren</span><br></pre></td></tr></table></figure>\n<p>直接保存到文件中</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> scrapy</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">LuarenSpider</span>(scrapy.Spider):</span><br><span class=\"line\">    name = <span class=\"string\">&quot;luaren&quot;</span> </span><br><span class=\"line\">    allowed_domains = [<span class=\"string\">&quot;lua.ren&quot;</span>]</span><br><span class=\"line\">    start_urls = [</span><br><span class=\"line\">        <span class=\"string\">&#x27;http://lua.ren/&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;http://lua.ren/topic/342/&#x27;</span></span><br><span class=\"line\">    ]        </span><br><span class=\"line\">      </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">parse</span>(<span class=\"params\">self, response</span>):</span><br><span class=\"line\">        filename = response.url.split(<span class=\"string\">&quot;/&quot;</span>)[-<span class=\"number\">2</span>] </span><br><span class=\"line\">        <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(filename, <span class=\"string\">&#x27;wb&#x27;</span>) <span class=\"keyword\">as</span> f: </span><br><span class=\"line\">            f.write(response.body)</span><br></pre></td></tr></table></figure>\n<p>保存到ORM中</p>\n<p>ORM定义</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> scrapy</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">RenItem</span>(scrapy.Item):</span><br><span class=\"line\">    title = scrapy.Field()</span><br><span class=\"line\">    link = scrapy.Field()</span><br><span class=\"line\">    desc = scrapy.Field()</span><br></pre></td></tr></table></figure>\n<p>爬虫</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> scrapy</span><br><span class=\"line\"><span class=\"keyword\">from</span> ren.items <span class=\"keyword\">import</span> RenItem</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">LuarenSpider</span>(scrapy.Spider):</span><br><span class=\"line\">    name = <span class=\"string\">&quot;luaren&quot;</span> </span><br><span class=\"line\">    allowed_domains = [<span class=\"string\">&quot;lua.ren&quot;</span>]</span><br><span class=\"line\">    start_urls = [</span><br><span class=\"line\">        <span class=\"string\">&#x27;http://lua.ren/&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;http://lua.ren/topic/342/&#x27;</span></span><br><span class=\"line\">    ]        </span><br><span class=\"line\">      </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">parse</span>(<span class=\"params\">self, response</span>):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> sel <span class=\"keyword\">in</span> response.xpath(<span class=\"string\">&#x27;//ul/li&#x27;</span>):</span><br><span class=\"line\">            item = RenItem() </span><br><span class=\"line\">            item[<span class=\"string\">&#x27;title&#x27;</span>] = sel.xpath(<span class=\"string\">&#x27;a/text()&#x27;</span>).extract()</span><br><span class=\"line\">            item[<span class=\"string\">&#x27;link&#x27;</span>] = sel.xpath(<span class=\"string\">&#x27;a/@href&#x27;</span>).extract()</span><br><span class=\"line\">            item[<span class=\"string\">&#x27;desc&#x27;</span>] = sel.xpath(<span class=\"string\">&#x27;text()&#x27;</span>).extract()</span><br><span class=\"line\">            <span class=\"keyword\">yield</span> item</span><br></pre></td></tr></table></figure>\n<p>先生成一堆的代码， 添加代码，按url进行依次访问，然的把body reponse通过回调返回给用用户处理，用户在cb中写自己的代码， xpath解析返回的数据，整个机制不是很复杂，不多说了。</p>\n<p>运行与保存结果为JSON数据。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scrapy crawl luaren</span><br><span class=\"line\">scrapy crawl luaren -o items.json</span><br></pre></td></tr></table></figure>","text":"看到别人的教程，学着测了一下，不错。 1scrapy startproject ren 直接保存到文件中 123456789101112131415# -*- coding: utf-8 -*-import scrapyclass LuarenSpider(scrapy.Spid...","link":"","photos":[],"count_time":{"symbolsCount":"1.5k","symbolsTime":"1 mins."},"categories":[{"name":"topic","slug":"topic","count":308,"path":"api/categories/topic.json"}],"tags":[],"toc":"","author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"从实现角度看Openresty + LUA = WAF","uid":"4b277b3bf21c49d9a15db633f740d15e","slug":"old_topic/2016-09-17-347","date":"2016-09-17T14:50:18.000Z","updated":"2024-03-16T11:44:51.883Z","comments":true,"path":"api/articles/old_topic/2016-09-17-347.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":[],"text":"作者：糖果 1.WAF存在形态 WAF就是WEB防火墙，Nginx Lua和Openresty的出现，让基于LUA开发的WAF更有可能。对所有 会造成安全威胁的HTTP请求数据，都应该成为安全检查策略应该关注的内容，笼统上来讲OR WAF的式样要求的输入数据，就是可以在WEB服务...","link":"","photos":[],"count_time":{"symbolsCount":"2.1k","symbolsTime":"2 mins."},"categories":[{"name":"topic","slug":"topic","count":308,"path":"api/categories/topic.json"}],"tags":[],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"用RESTY-HTTP实现Graylog的Widget更新与查询","uid":"07e149df00baf09dc3d8d5e82a638745","slug":"old_topic/2016-09-17-350","date":"2016-09-17T14:50:18.000Z","updated":"2024-03-16T11:44:51.885Z","comments":true,"path":"api/articles/old_topic/2016-09-17-350.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"text":"作者：糖果 MoonScript for GrayLog是之前写的一个基于Lapis与Simple HTTP的Graylog日志查询SDK， 支持Stream查询，最近为了做自动化分析，加入了新的接口中调用功能，加入了对Dashboard widgets和更新与查询，通过这个程序...","link":"","photos":[],"count_time":{"symbolsCount":"2.9k","symbolsTime":"3 mins."},"categories":[{"name":"topic","slug":"topic","count":308,"path":"api/categories/topic.json"}],"tags":[],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}}}