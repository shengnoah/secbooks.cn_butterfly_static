{"title":"距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间","uid":"7e39ea8bf1e59b18cfe1f80ce00c3293","slug":"weibo/距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间","date":"2024-03-17T14:44:59.199Z","updated":"2024-03-16T11:44:51.937Z","comments":true,"path":"api/articles/weibo/距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"content":"<h1 id=\"距离机器人-ai-的-chatgpt-时刻大约还有-3-年时间\"><a class=\"markdownIt-Anchor\" href=\"#距离机器人-ai-的-chatgpt-时刻大约还有-3-年时间\"></a> 距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间</h1>\n<p>距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间</p>\n<p>英伟达 AI 科学家 Jim Fan 预言：距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间</p>\n<p>以下为其推文转译：</p>\n<p>除了大语言模型（LLM）之外，2024年最重大的领域无疑是机器人学。我们距离实体 AI 智能体实现 ChatGPT 式的突破仅有大约三年的时间。长期以来，我们一直受到莫拉维克悖论（Moravec’s paradox）的困扰，这一直觉反常的现象表明：“人类觉得简单的任务，对 AI 来说却异常困难，反之亦然”。</p>\n<p>2024年将成为 AI 领域首次大规模反抗这种困境的一年。虽然我们不会立刻取得胜利，但我们已经在通往成功的道路上迈出了坚实的步伐。</p>\n<p>回顾2023年，我们已经初步见识到了未来机器人的基础模型和平台：</p>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>多模态大型语言模型与机器人手臂作为物理输入输出接口：VIMA、PerAct、RvT（NVIDIA）、RT-1、RT-2、PaLM-E（Google）、RoboCat（DeepMind）、Octo（伯克利、斯坦福、卡内基梅隆大学）等。</p>\n</li>\n<li class=\"lvl-2\">\n<p>连接高级推理（大型语言模型）与低级控制的算法：Eureka（NVIDIA）、Code as Policies（Google）等。</p>\n</li>\n<li class=\"lvl-2\">\n<p>在坚固硬件方面取得巨大进步：Tesla Optimus <a href=\"https://weibo.com/n/elonmusk\">@elonmusk</a>、Figure <a href=\"https://weibo.com/n/adcock_brett\">@adcock_brett</a>、1X <a href=\"https://weibo.com/n/ericjang11\">@ericjang11</a>、Apptronik、Sanctuary、Agility+Amazon、Unitree 等。</p>\n</li>\n<li class=\"lvl-2\">\n<p>数据长期以来一直是机器人学发展的弱点。研究社区正致力于创造下一个“影像网”（ImageNet），如 Open X-Embodiment (RT-X) 数据集。尽管这些数据集的多样性尚未达到理想状态，但即使是微小的进步也意味着重大的飞跃。</p>\n</li>\n<li class=\"lvl-2\">\n<p>在解决机器人灵活性甚至整个计算机视觉领域中，仿真和合成数据将扮演关键角色。<br />\n(1) NVIDIA Isaac 能以比现实时间快1000倍的速度进行仿真，其产生的数据量会随着计算能力的提升而增长。<br />\n(2) 通过硬件加速的光线追踪技术实现逼真效果，这种逼真的渲染还自带地面真值标注，比如分割、深度、3D 姿态等。<br />\n(3) 仿真器甚至能够扩展现实世界的数据，形成更大的数据集，从而大大减少昂贵的人类示范工作的需要。NVIDIA 的 MimicGen 就是一个很好的例子。</p>\n</li>\n</ul>\n<p>我个人全力投入这一领域。最精彩的部分还在后面。</p>\n","text":" 距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间 距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间 英伟达 AI 科学家 Jim Fan 预言：距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间 以下为其推文转译： 除了大语言模型（LLM...","link":"","photos":[],"count_time":{"symbolsCount":"1.1k","symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":119,"path":"api/categories/AIGC.json"},{"name":"weibo","slug":"AIGC/weibo","count":59,"path":"api/categories/AIGC/weibo.json"}],"tags":[{"name":"weibo","slug":"weibo","count":62,"path":"api/tags/weibo.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E8%B7%9D%E7%A6%BB%E6%9C%BA%E5%99%A8%E4%BA%BA-ai-%E7%9A%84-chatgpt-%E6%97%B6%E5%88%BB%E5%A4%A7%E7%BA%A6%E8%BF%98%E6%9C%89-3-%E5%B9%B4%E6%97%B6%E9%97%B4\"><span class=\"toc-text\"> 距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间</span></a></li></ol>","author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"GPT2与GPT3的区别是什么？","uid":"17c7f8a2a28343c5bbea587ebdcd485c","slug":"zhihu/GPT2与GPT3的区别是什么？","date":"2024-03-17T14:44:59.208Z","updated":"2024-03-16T11:44:51.938Z","comments":true,"path":"api/articles/zhihu/GPT2与GPT3的区别是什么？.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"text":" GPT2与GPT3的区别是什么？ GPT2和GPT3之间的主要区别是模型的大小。GPT2模型的参数大约为1.5亿，而GPT3模型的参数大约为175亿。此外，GPT2是通过预先训练一个语言模型来实现的，而GPT3是一个通过机器学习不断训练的深度神经网络。因此，GPT3可以在新的任...","link":"","photos":[],"count_time":{"symbolsCount":164,"symbolsTime":"1 mins."},"categories":[{"name":"文章","slug":"文章","count":22,"path":"api/categories/文章.json"}],"tags":[{"name":"Ruby","slug":"Ruby","count":5,"path":"api/tags/Ruby.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"视频一致性模型（VideoLCM）","uid":"034f4a0d42715b75637c06564678c3f4","slug":"weibo/视频一致性模型（VideoLCM）","date":"2024-03-17T14:44:59.196Z","updated":"2024-03-16T11:44:51.937Z","comments":true,"path":"api/articles/weibo/视频一致性模型（VideoLCM）.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":[],"text":"第一个视频一致性模型（VideoLCM）也来了！ 我们之前介绍过图像的LCM（访问微博正文，微博正文），现在视频的LCM也开始卷起来了。 它只需 4 个采样步骤即可生成视频：生成 16 帧（分辨率为 256x256）仅需 10 秒！虽然还不是实时的（像图像LCM那样），但已经接近...","link":"","photos":[],"count_time":{"symbolsCount":572,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":119,"path":"api/categories/AIGC.json"}],"tags":[{"name":"AIGC","slug":"AIGC","count":6,"path":"api/tags/AIGC.json"},{"name":"LLM","slug":"LLM","count":4,"path":"api/tags/LLM.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}}}