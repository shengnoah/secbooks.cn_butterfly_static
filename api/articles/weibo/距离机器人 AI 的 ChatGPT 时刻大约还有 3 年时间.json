{"title":"距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间","uid":"7e39ea8bf1e59b18cfe1f80ce00c3293","slug":"weibo/距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间","date":"2024-03-16T11:44:51.937Z","updated":"2024-03-16T11:44:51.937Z","comments":true,"path":"api/articles/weibo/距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"content":"<h1 id=\"距离机器人-ai-的-chatgpt-时刻大约还有-3-年时间\"><a class=\"markdownIt-Anchor\" href=\"#距离机器人-ai-的-chatgpt-时刻大约还有-3-年时间\"></a> 距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间</h1>\n<p>距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间</p>\n<p>英伟达 AI 科学家 Jim Fan 预言：距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间</p>\n<p>以下为其推文转译：</p>\n<p>除了大语言模型（LLM）之外，2024年最重大的领域无疑是机器人学。我们距离实体 AI 智能体实现 ChatGPT 式的突破仅有大约三年的时间。长期以来，我们一直受到莫拉维克悖论（Moravec’s paradox）的困扰，这一直觉反常的现象表明：“人类觉得简单的任务，对 AI 来说却异常困难，反之亦然”。</p>\n<p>2024年将成为 AI 领域首次大规模反抗这种困境的一年。虽然我们不会立刻取得胜利，但我们已经在通往成功的道路上迈出了坚实的步伐。</p>\n<p>回顾2023年，我们已经初步见识到了未来机器人的基础模型和平台：</p>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>多模态大型语言模型与机器人手臂作为物理输入输出接口：VIMA、PerAct、RvT（NVIDIA）、RT-1、RT-2、PaLM-E（Google）、RoboCat（DeepMind）、Octo（伯克利、斯坦福、卡内基梅隆大学）等。</p>\n</li>\n<li class=\"lvl-2\">\n<p>连接高级推理（大型语言模型）与低级控制的算法：Eureka（NVIDIA）、Code as Policies（Google）等。</p>\n</li>\n<li class=\"lvl-2\">\n<p>在坚固硬件方面取得巨大进步：Tesla Optimus <a href=\"https://weibo.com/n/elonmusk\">@elonmusk</a>、Figure <a href=\"https://weibo.com/n/adcock_brett\">@adcock_brett</a>、1X <a href=\"https://weibo.com/n/ericjang11\">@ericjang11</a>、Apptronik、Sanctuary、Agility+Amazon、Unitree 等。</p>\n</li>\n<li class=\"lvl-2\">\n<p>数据长期以来一直是机器人学发展的弱点。研究社区正致力于创造下一个“影像网”（ImageNet），如 Open X-Embodiment (RT-X) 数据集。尽管这些数据集的多样性尚未达到理想状态，但即使是微小的进步也意味着重大的飞跃。</p>\n</li>\n<li class=\"lvl-2\">\n<p>在解决机器人灵活性甚至整个计算机视觉领域中，仿真和合成数据将扮演关键角色。<br />\n(1) NVIDIA Isaac 能以比现实时间快1000倍的速度进行仿真，其产生的数据量会随着计算能力的提升而增长。<br />\n(2) 通过硬件加速的光线追踪技术实现逼真效果，这种逼真的渲染还自带地面真值标注，比如分割、深度、3D 姿态等。<br />\n(3) 仿真器甚至能够扩展现实世界的数据，形成更大的数据集，从而大大减少昂贵的人类示范工作的需要。NVIDIA 的 MimicGen 就是一个很好的例子。</p>\n</li>\n</ul>\n<p>我个人全力投入这一领域。最精彩的部分还在后面。</p>\n","text":" 距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间 距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间 英伟达 AI 科学家 Jim Fan 预言：距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间 以下为其推文转译： 除了大语言模型（LLM...","link":"","photos":[],"count_time":{"symbolsCount":"1.1k","symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":119,"path":"api/categories/AIGC.json"},{"name":"weibo","slug":"AIGC/weibo","count":59,"path":"api/categories/AIGC/weibo.json"}],"tags":[{"name":"weibo","slug":"weibo","count":62,"path":"api/tags/weibo.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E8%B7%9D%E7%A6%BB%E6%9C%BA%E5%99%A8%E4%BA%BA-ai-%E7%9A%84-chatgpt-%E6%97%B6%E5%88%BB%E5%A4%A7%E7%BA%A6%E8%BF%98%E6%9C%89-3-%E5%B9%B4%E6%97%B6%E9%97%B4\"><span class=\"toc-text\"> 距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间</span></a></li></ol>","author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"视频一致性模型（VideoLCM）","uid":"034f4a0d42715b75637c06564678c3f4","slug":"weibo/视频一致性模型（VideoLCM）","date":"2024-03-16T11:44:51.937Z","updated":"2024-03-16T11:44:51.937Z","comments":true,"path":"api/articles/weibo/视频一致性模型（VideoLCM）.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":[],"text":"第一个视频一致性模型（VideoLCM）也来了！ 我们之前介绍过图像的LCM（访问微博正文，微博正文），现在视频的LCM也开始卷起来了。 它只需 4 个采样步骤即可生成视频：生成 16 帧（分辨率为 256x256）仅需 10 秒！虽然还不是实时的（像图像LCM那样），但已经接近...","link":"","photos":[],"count_time":{"symbolsCount":572,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":119,"path":"api/categories/AIGC.json"}],"tags":[{"name":"AIGC","slug":"AIGC","count":6,"path":"api/tags/AIGC.json"},{"name":"LLM","slug":"LLM","count":4,"path":"api/tags/LLM.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"如何突破原生家庭","uid":"b6fef9df2a9c64f23a57b2b7ab6bf664","slug":"weibo/如何突破原生家庭","date":"2024-03-16T11:44:51.935Z","updated":"2024-03-16T11:44:51.935Z","comments":true,"path":"api/articles/weibo/如何突破原生家庭.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"text":" 如何突破原生家庭 人受家庭影响最大，这一点毋容置疑。家庭的社会经济地位和资源，父母对孩子发展的支持度，以及父母本身的人生观世界观和心理素养都对孩子的影响最大 父母决定了会把孩子送去怎样的学校读书，也决定了孩子未来的兴趣启蒙，这对几乎所有的人来说都是不可抗拒的自然力 社会能做的的...","link":"","photos":[],"count_time":{"symbolsCount":"1.8k","symbolsTime":"2 mins."},"categories":[{"name":"classical","slug":"classical","count":6,"path":"api/categories/classical.json"}],"tags":[{"name":"article","slug":"article","count":4,"path":"api/tags/article.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}}}