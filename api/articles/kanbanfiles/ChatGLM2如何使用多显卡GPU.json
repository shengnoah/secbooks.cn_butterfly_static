{"title":"ChatGLM2如何使用多显卡GPU","uid":"db337d0c1275ad3ba82eaea7216e78e0","slug":"kanbanfiles/ChatGLM2如何使用多显卡GPU","date":"2024-03-16T11:44:51.795Z","updated":"2024-03-16T11:44:51.795Z","comments":true,"path":"api/articles/kanbanfiles/ChatGLM2如何使用多显卡GPU.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"content":"<h2 id=\"chatglm2的trainsh的num_gpus如何设置配置双显卡\"><a class=\"markdownIt-Anchor\" href=\"#chatglm2的trainsh的num_gpus如何设置配置双显卡\"></a> ChatGLM2的train.sh的NUM_GPUS如何设置配置双显卡？</h2>\n<p>ChatGLM和ChatGLM2，对GPU配置的传参数样式不太一样，一代的时候，“0,1”这么用双显卡，二代的时候直接输入NUM_GPUS=2.</p>\n<p>要配置双显卡进行训练，可以将NUM_GPUS设置为2，以表示使用两个GPU。以下是一个示例的train.sh文件的内容：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> NUM_GPUS=2</span><br><span class=\"line\"></span><br><span class=\"line\">python train.py \\</span><br><span class=\"line\">  --data_dir=data \\</span><br><span class=\"line\">  --model_dir=model \\</span><br><span class=\"line\">  --num_gpus=<span class=\"variable\">$NUM_GPUS</span> \\</span><br><span class=\"line\">  --batch_size=64 \\</span><br><span class=\"line\">  --learning_rate=0.001</span><br></pre></td></tr></table></figure>\n<p>在这个示例中，将NUM_GPUS设置为2，并传递给train.py脚本的–num_gpus参数。根据你的需求，你可以调整其他参数，例如数据目录、模型目录、批量大小和学习率等。</p>\n<p>请注意，具体的命令可能会根据ChatGLM2的实际代码库有所不同，请根据你使用的代码库和框架进行相应调整。</p>\n<h2 id=\"chatglm2如何使用多显卡gpu\"><a class=\"markdownIt-Anchor\" href=\"#chatglm2如何使用多显卡gpu\"></a> ChatGLM2如何使用多显卡GPU</h2>\n<p>要在ChatGLM2中使用多个显卡GPU，你需要使用分布式训练的方法。以下是一个使用多个显卡GPU进行ChatGLM2训练的示例：</p>\n<ol>\n<li class=\"lvl-3\">\n<p>确保你的计算机上有多个显卡GPU，并安装了相应的驱动程序。</p>\n</li>\n<li class=\"lvl-3\">\n<p>使用<code>transformers</code>库加载ChatGLM2模型和tokenizer：</p>\n</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> transformers <span class=\"keyword\">import</span> ChatGPT</span><br><span class=\"line\"></span><br><span class=\"line\">model = ChatGPT.from_pretrained(<span class=\"string\">&quot;microsoft/DialoGPT-medium&quot;</span>)</span><br><span class=\"line\">tokenizer = AutoTokenizer.from_pretrained(<span class=\"string\">&quot;microsoft/DialoGPT-medium&quot;</span>)</span><br></pre></td></tr></table></figure>\n<ol start=\"3\">\n<li class=\"lvl-3\">\n<p>使用<code>torch.nn.DataParallel</code>将模型包装在多个GPU上：</p>\n</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\">device = torch.device(<span class=\"string\">&quot;cuda&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;cpu&quot;</span>)</span><br><span class=\"line\">model = nn.DataParallel(model)</span><br><span class=\"line\">model.to(device)</span><br></pre></td></tr></table></figure>\n<ol start=\"4\">\n<li class=\"lvl-3\">\n<p>在训练循环中，确保将输入数据和目标标签移动到正确的设备上：</p>\n</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">input_ids = input_ids.to(device)</span><br><span class=\"line\">attention_mask = attention_mask.to(device)</span><br><span class=\"line\">labels = labels.to(device)</span><br><span class=\"line\"></span><br><span class=\"line\">outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)</span><br></pre></td></tr></table></figure>\n<p>这样，模型就会自动在多个显卡GPU上并行计算，并共享梯度更新。</p>\n<p>请注意，使用多个显卡GPU进行训练可能需要更大的批次大小和更长的训练时间。此外，还可以通过设置CUDA_VISIBLE_DEVICES环境变量来选择要使用的特定GPU设备。</p>\n","text":" ChatGLM2的train.sh的NUM_GPUS如何设置配置双显卡？ ChatGLM和ChatGLM2，对GPU配置的传参数样式不太一样，一代的时候，“0,1”这么用双显卡，二代的时候直接输入NUM_GPUS=2. 要配置双显卡进行训练，可以将NUM_GPUS设置为2，以表...","link":"","photos":[],"count_time":{"symbolsCount":"1.4k","symbolsTime":"1 mins."},"categories":[{"name":"ChatGLM","slug":"ChatGLM","count":1,"path":"api/categories/ChatGLM.json"}],"tags":[{"name":"ChatGLM2","slug":"ChatGLM2","count":1,"path":"api/tags/ChatGLM2.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#chatglm2%E7%9A%84trainsh%E7%9A%84num_gpus%E5%A6%82%E4%BD%95%E8%AE%BE%E7%BD%AE%E9%85%8D%E7%BD%AE%E5%8F%8C%E6%98%BE%E5%8D%A1\"><span class=\"toc-text\"> ChatGLM2的train.sh的NUM_GPUS如何设置配置双显卡？</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#chatglm2%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E5%A4%9A%E6%98%BE%E5%8D%A1gpu\"><span class=\"toc-text\"> ChatGLM2如何使用多显卡GPU</span></a></li></ol>","author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"","uid":"f73a8e23e6f6f669cf99c7dba8fa0722","slug":"kanbanfiles/Kali上的弱口令扫描工具","date":"2024-03-16T11:44:51.796Z","updated":"2024-03-16T11:44:51.796Z","comments":true,"path":"api/articles/kanbanfiles/Kali上的弱口令扫描工具.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"text":"Kali上的弱口令扫描工具有那些可以使用？ 在Kali上有很多弱口令扫描工具可以使用，以下是一些常见的工具： Hydra：Hydra是一个强大的登录破解工具，支持多种协议和服务，可以用于进行弱口令扫描。 Medusa：Medusa也是一个密码破解工具，类似于Hydra，支持多种协...","link":"","photos":[],"count_time":{"symbolsCount":"1.5k","symbolsTime":"1 mins."},"categories":[],"tags":[],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"","uid":"f73a8e23e6f6f669cf99c7dba8fa0722","slug":"kanbanfiles/ATT&CK技术","date":"2024-03-16T11:44:51.795Z","updated":"2024-03-16T11:44:51.795Z","comments":true,"path":"api/articles/kanbanfiles/ATT&CK技术.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"text":"ATT&CK技术指是什么？ ATT&CK技术指的是一种用于描述和分类威胁行为的系统。ATT&CK代表Adversarial Tactics, Techniques, and Common Knowledge（对抗性战术、技术和共享知识），是由MITRE公司开发并维护的一套框架。 ...","link":"","photos":[],"count_time":{"symbolsCount":366,"symbolsTime":"1 mins."},"categories":[],"tags":[],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}}}