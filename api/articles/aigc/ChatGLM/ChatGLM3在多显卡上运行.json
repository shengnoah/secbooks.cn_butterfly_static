{"title":"ChaGLM3在多显卡上运行","uid":"c8a161f78cff976f698872281578706e","slug":"aigc/ChatGLM/ChatGLM3在多显卡上运行","date":"2024-03-17T14:44:56.661Z","updated":"2024-03-16T11:44:51.771Z","comments":true,"path":"api/articles/aigc/ChatGLM/ChatGLM3在多显卡上运行.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"content":"<h1 id=\"chaglm3在多显卡上运行\"><a class=\"markdownIt-Anchor\" href=\"#chaglm3在多显卡上运行\"></a> ChaGLM3在多显卡上运行</h1>\n<p>在明确是16位量化的时候，用ChatGLM项目中的utils文件的load_model_on_gpus方法，进行对model的配置， num_gpus=4,意思是说在4块显卡上运行。<br />\nfrom utils import load_model_on_gpus</p>\n<p>model = load_model_on_gpus(model_name, num_gpus=4)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> quantize == <span class=\"number\">16</span>:</span><br><span class=\"line\">model = load_model_on_gpus(model_name, num_gpus=<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"keyword\">else</span>:</span><br><span class=\"line\">model = AutoModel.from_pretrained(model_name, device_map=<span class=\"string\">&quot;auto&quot;</span>,trust_remote_code=<span class=\"literal\">True</span>).half().quantize(quantize).cuda()</span><br></pre></td></tr></table></figure>\n<p>运行的时候，用命令参数 -d，指定所在运行的显卡。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">parser.add_argument(<span class=\"string\">&#x27;--device&#x27;</span>, <span class=\"string\">&#x27;-d&#x27;</span>, <span class=\"built_in\">help</span>=<span class=\"string\">&#x27;device， -1 means cpu, other means gpu ids&#x27;</span>, default=<span class=\"string\">&#x27;0&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python fastapiGPU.py -d 0,1,2,3</span><br></pre></td></tr></table></figure>\n<p>相当于SD的 CUDA_VISIBLE_DEVICES。</p>\n<p>webui-user.sh中加入export参数。</p>\n<p>export CUDA_VISIBLE_DEVICES=0,1,2,3</p>\n<p>./stable-diffusion-webui/webui.sh --listen --device-id 1<br />\n这样运行，SD可以同时使用显卡0和显卡1.</p>\n<p>CUDA_VISIBLE_DEVICES=0,1,2,3 python <a href=\"http://launch.py\">launch.py</a>  --share</p>\n<p>CUDA_VISIBLE_DEVICES=1 python <a href=\"http://launch.py\">launch.py</a>  --share</p>\n<p>cmd_args.py    --device-id</p>\n<p>device-id参数是在cmd_args.py文件中出现的。</p>\n","text":" ChaGLM3在多显卡上运行 在明确是16位量化的时候，用ChatGLM项目中的utils文件的load_model_on_gpus方法，进行对model的配置， num_gpus=4,意思是说在4块显卡上运行。 from utils import load_model_on_...","link":"","photos":[],"count_time":{"symbolsCount":938,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":119,"path":"api/categories/AIGC.json"},{"name":"chatglm3","slug":"AIGC/chatglm3","count":1,"path":"api/categories/AIGC/chatglm3.json"}],"tags":[{"name":"chatglm3","slug":"chatglm3","count":1,"path":"api/tags/chatglm3.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#chaglm3%E5%9C%A8%E5%A4%9A%E6%98%BE%E5%8D%A1%E4%B8%8A%E8%BF%90%E8%A1%8C\"><span class=\"toc-text\"> ChaGLM3在多显卡上运行</span></a></li></ol>","author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"gpt4all","uid":"bc3e68a199458a681f2c7fe3b421bbd6","slug":"aigc/langchain/GPT4all Embeddings","date":"2024-03-17T14:44:56.668Z","updated":"2024-03-16T11:44:51.772Z","comments":true,"path":"api/articles/aigc/langchain/GPT4all Embeddings.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"text":" gpt4all 1pip install gpt4all Embeddings 翻译成中文为“嵌入”，是指将一个数据集或模型的特征值映射到一个更小的向量空间内的过程。在计算机自然语言处理领域中，Embeddings 通常被用来表示文本、图像或其他数据类型的特征，并使得模型能够更...","link":"","photos":[],"count_time":{"symbolsCount":"3.4k","symbolsTime":"3 mins."},"categories":[{"name":"gpt4all","slug":"gpt4all","count":1,"path":"api/categories/gpt4all.json"}],"tags":[{"name":"gpt4all","slug":"gpt4all","count":1,"path":"api/tags/gpt4all.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"长文本能力会不会杀死RAG","uid":"124bb865c7cb77ee9606b987c0e9b277","slug":"aigc/长文本能力会不会杀死RAG","date":"2024-03-17T14:44:56.654Z","updated":"2024-03-16T11:44:51.779Z","comments":true,"path":"api/articles/aigc/长文本能力会不会杀死RAG.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"text":" 长文本能力会不会杀死RAG 随着 Gemini 超100万上下文的推出，推特上关于长文本能力会不会杀死RAG的讨论还是挺多的。围绕 RAG vs 长文本的成本的讨论还比较多，例如图1，但也有说法认为，长文本的成本会慢慢下降。 看到一个还不错的长推特评论，来自 Snorkel A...","link":"","photos":[],"count_time":{"symbolsCount":544,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":119,"path":"api/categories/AIGC.json"},{"name":"rag","slug":"AIGC/rag","count":1,"path":"api/categories/AIGC/rag.json"}],"tags":[{"name":"RAG","slug":"RAG","count":2,"path":"api/tags/RAG.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}}}